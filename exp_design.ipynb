{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are overhauling the experimental design (i.e. stimuli) for the upcoming V1 acute experiment - expected start date is the week of December 11th, 2017. Now that our interest lies in the interaction between contrast and spectral dispersion rather than just spectral dispersion, we will present our stimuli at more contrasts. To compensate for more contrasts, we will reduce the number of dispersion families.\n",
    "\n",
    "We also plan to more carefully choose our contrasts and spatial frequencies of both our single gratings and our dispersed stimuli so that we can completely make linear predictions for all presented stimuli. In short, any grating which appears as part of a dispersed grating will also be presented in isolation with the exact same contrast and spatial frequency. To ensure compatability of the data sets, we hope to keep the contrast profile (as a function of spatial frequency) similar to that used in the previous sfMix experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "verbose = 1; # print some output?\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous experimental design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spatial frequency centers were: [  0.3    0.43   0.6    0.86   1.22   1.73   2.46   3.49   4.96   7.04  10.  ]\n",
      "The gratings of each dispersed stimuli were separated by 0.375 octaves\n",
      "The contrast profiles are as follows:\n",
      "Family 1: [ 0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "Family 2: [ 0.     0.     0.002  0.162  0.672  0.162  0.002  0.     0.   ]\n",
      "Family 3: [ 0.     0.007  0.063  0.241  0.378  0.241  0.063  0.007  0.   ]\n",
      "Family 4: [ 0.022  0.06   0.122  0.187  0.216  0.187  0.122  0.06   0.022]\n",
      "Family 5: [ 0.071  0.097  0.121  0.139  0.145  0.139  0.121  0.097  0.071]\n"
     ]
    }
   ],
   "source": [
    "sfCenters = np.logspace(np.log10(0.3), np.log10(10), 11)\n",
    "\n",
    "nGrats = 9; # 9 gratings make up the stimulus\n",
    "dispSpread = 1.5; # 1.5 octaves on either side of the center\n",
    "octSeries = np.linspace(dispSpread, -dispSpread, nGrats)\n",
    "octStep = np.abs(np.unique(np.diff(octSeries)))\n",
    "\n",
    "nFam = 5;\n",
    "spreadVec = np.logspace(np.log10(.125), np.log10(1.25), nFam);\n",
    "conProf = np.zeros((nFam, nGrats));\n",
    "for i in range(nFam):\n",
    "    profTemp = norm.pdf(octSeries, 0, spreadVec[i]);\n",
    "    conProf[i] = profTemp / np.sum(profTemp)\n",
    "    if i == 0:\n",
    "        conProf[i] = np.round(conProf[i], 0) # we made the lowest dispersion just a single grating\n",
    "    \n",
    "if verbose:\n",
    "    print('The spatial frequency centers were: ' + str(np.round(sfCenters, 2)));\n",
    "    print('The gratings of each dispersed stimuli were separated by ' + str(np.round(octStep[0], 3)) + ' octaves');\n",
    "    print('The contrast profiles are as follows:')\n",
    "    for i in range(nFam):\n",
    "        print('Family ' + str(i+1) + ': ' + str(np.round(conProf[i], 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment length (in minutes) without blanks: 22.67\n"
     ]
    }
   ],
   "source": [
    "nCondSfMix = nFam*2*len(sfCenters) # 2 for 2 contrasts (high/low)\n",
    "nCondCRF = 10; # 10 contrasts, 1 SF\n",
    "nCondOri = 16; # ori16\n",
    "nTrials = 10*(nCondSfMix + nCondCRF + nCondOri);\n",
    "if verbose:\n",
    "    print('Experiment length (in minutes) without blanks: ' + str(np.round(nTrials/60.0, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting the spatial frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Expo program, we have a free parameter \"sfRel\" which permits a shifting of the spatial frequencies used. For example, if a cell has a fairly low high-frequency cutoff, we can have sfRel lower than the \"standard\" (1.73) so that more spatial frequencies are in the pass-band of such a low-pass cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SF multipliers are:\n",
      "\t[ 0.173205  0.245951  0.34925   0.495934  0.704226  1.        1.419998\n",
      "  2.016396  2.863279  4.065851  5.773503]\n"
     ]
    }
   ],
   "source": [
    "defaultSfs = np.logspace(np.log10(0.3), np.log10(10), 11)\n",
    "sfAnchor = np.median(defaultSfs);\n",
    "sfMult = sfAnchor / defaultSfs\n",
    "if verbose:\n",
    "    print('SF multipliers are:\\n\\t' + str(np.round(np.sort(sfMult), 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With sfRel 1.73 cpd, new sfCenters are\n",
      "\t[ 0.3   0.43  0.6   0.86  1.22  1.73  2.46  3.49  4.95  7.03  9.99]\n"
     ]
    }
   ],
   "source": [
    "sfRel = 1.73\n",
    "sfShifts = sfRel * sfMult\n",
    "if verbose:\n",
    "    print('With sfRel ' + str(sfRel) + ' cpd, new sfCenters are\\n\\t' + str(np.round(np.sort(sfShifts), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New experimental design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First attempt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42599954,  0.60491869,  0.85898361,  1.21975541,  1.73205081,\n",
       "        2.45950949,  3.49249969,  4.9593442 ,  7.04226114])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfAll[int(sfsLost[1]/2):nSfsTot-int(sfsLost[1]/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispersion level 1 sf centers:[  0.3    0.43   0.6    0.86   1.22   1.73   2.46   3.49   4.96   7.04  10.  ]\n",
      "Dispersion level 2 sf centers:[ 0.43  0.6   0.86  1.22  1.73  2.46  3.49  4.96  7.04]\n",
      "Dispersion level 3 sf centers:[ 0.6   0.86  1.22  1.73  2.46  3.49  4.96]\n",
      "Dispersion level 4 sf centers:[ 0.86  1.22  1.73  2.46  3.49]\n"
     ]
    }
   ],
   "source": [
    "nDisps = 4;\n",
    "\n",
    "nSfsTot = 11;\n",
    "sfsLost = [0, 2, 4, 6];\n",
    "sfMin = 0.3;\n",
    "sfMax = 10;\n",
    "\n",
    "nSfCenters = np.subtract(nSfsTot, sfsLost)\n",
    "sfAll = np.logspace(np.log10(sfMin), np.log10(sfMax), nSfsTot)\n",
    "sfCenters = [sfAll[sfsLost[0]:nSfsTot-sfsLost[0]], sfAll[int(sfsLost[1]/2):nSfsTot-int(sfsLost[1]/2)], \n",
    "             sfAll[int(sfsLost[2]/2):nSfsTot-int(sfsLost[2]/2)], sfAll[int(sfsLost[3]/2):nSfsTot-int(sfsLost[3]/2)]];\n",
    "\n",
    "nCons = 9;\n",
    "nSfMixCons = 4;\n",
    "conMin = 0.05;\n",
    "conMax = 1;\n",
    "\n",
    "if verbose:\n",
    "    for i in range(nDisps):\n",
    "        print('Dispersion level ' + str(i+1) + ' sf centers:' + str(np.round(sfCenters[i], 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con min = 0.05; Con max = 1; use 9 contrasts\n",
      "If we logarithmically space the contrasts, we get the following:\n",
      "\t[ 0.05   0.073  0.106  0.154  0.224  0.325  0.473  0.688  1.   ]\n",
      "Rounded to the nearest hundredth, we get:\n",
      "\t[ 0.05  0.07  0.11  0.15  0.22  0.33  0.47  0.69  1.  ]\n"
     ]
    }
   ],
   "source": [
    "logCons = np.logspace(np.log10(conMin), np.log10(conMax), nCons);\n",
    "if verbose:\n",
    "    print('Con min = ' + str(conMin) + '; Con max = ' + str(conMax) + '; use ' + str(nCons) + ' contrasts')\n",
    "    print('If we logarithmically space the contrasts, we get the following:\\n\\t' + str(np.round(logCons, 3)))\n",
    "    print('Rounded to the nearest hundredth, we get:\\n\\t' + str(np.round(logCons, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profs = [];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total contrast = 1\n",
      "Family 1: [ 1.] /// sum = 1.0\n",
      "Family 2: [ 0.154  0.688  0.154] /// sum = 1.0\n",
      "Family 3: [ 0.106  0.224  0.325  0.224  0.106] /// sum = 0.98\n",
      "Family 4: [ 0.073  0.106  0.154  0.325  0.154  0.106  0.073] /// sum = 0.99\n"
     ]
    }
   ],
   "source": [
    "profs.append([]);\n",
    "d1cent = -1;\n",
    "d2cent = 7;\n",
    "d3cent = 5;\n",
    "d4cent = 5;\n",
    "profs[0].append([logCons[d1cent]]);\n",
    "profs[0].append([logCons[d2cent-4], logCons[d2cent], logCons[d2cent-4]]);\n",
    "profs[0].append([logCons[d3cent-3], logCons[d3cent-1], logCons[d3cent], logCons[d3cent-1], logCons[d3cent-3]]);\n",
    "profs[0].append([logCons[d4cent-4], logCons[d4cent-3], logCons[d4cent-2], logCons[d4cent], logCons[d4cent-2], logCons[d4cent-3], logCons[d4cent-4]]);\n",
    "# profs1.append([logCons[1], logCons[2], logCons[3], logCons[4], logCons[3], logCons[2], logCons[1]])\n",
    "\n",
    "if verbose:\n",
    "    print('Total contrast = 1')\n",
    "    for i in range(nDisps):\n",
    "        print('Family ' + str(i+1) + ': ' + str(np.round(profs[0][i], 3)) + ' /// sum = ' + str(np.round(np.sum(profs[0][i]), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total contrast = 0.69\n",
      "Family 1: [ 0.688] /// sum = 0.69\n",
      "Family 2: [ 0.106  0.473  0.106] /// sum = 0.68\n",
      "Family 3: [ 0.073  0.154  0.224  0.154  0.073] /// sum = 0.68\n",
      "Family 4: [ 0.05   0.073  0.106  0.224  0.106  0.073  0.05 ] /// sum = 0.68\n"
     ]
    }
   ],
   "source": [
    "profs.append([]);\n",
    "d1cent = -2;\n",
    "d2cent = 6;\n",
    "d3cent = 4;\n",
    "d4cent = 4;\n",
    "profs[1].append([logCons[-2]]);\n",
    "profs[1].append([logCons[d2cent-4], logCons[d2cent], logCons[d2cent-4]]);\n",
    "profs[1].append([logCons[d3cent-3], logCons[d3cent-1], logCons[d3cent], logCons[d3cent-1], logCons[d3cent-3]]);\n",
    "profs[1].append([logCons[d4cent-4], logCons[d4cent-3], logCons[d4cent-2], logCons[d4cent], logCons[d4cent-2], logCons[d4cent-3], logCons[d4cent-4]]);\n",
    "\n",
    "if verbose:\n",
    "    print('Total contrast = ' + str(np.round(logCons[d1cent], 2)))\n",
    "    for i in range(nDisps):\n",
    "        print('Family ' + str(i+1) + ': ' + str(np.round(profs[1][i], 3)) + ' /// sum = ' + str(np.round(np.sum(profs[1][i]), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total contrast = 0.47\n",
      "Family 1: [ 0.473] /// sum = 0.47\n",
      "Family 2: [ 0.073  0.325  0.073] /// sum = 0.47\n",
      "Family 3: [ 0.05   0.106  0.154  0.106  0.05 ] /// sum = 0.47\n"
     ]
    }
   ],
   "source": [
    "profs.append([]);\n",
    "d1cent = -3;\n",
    "d2cent = 5;\n",
    "d3cent = 3;\n",
    "profs[2].append([logCons[d1cent]]);\n",
    "profs[2].append([logCons[d2cent-4], logCons[d2cent], logCons[d2cent-4]]);\n",
    "profs[2].append([logCons[d3cent-3], logCons[d3cent-1], logCons[d3cent], logCons[d3cent-1], logCons[d3cent-3]]);\n",
    "# profs.append([logCons[0], logCons[1], logCons[2], logCons[3], logCons[2], logCons[1], logCons[0]])\n",
    "\n",
    "if verbose:\n",
    "    print('Total contrast = ' + str(np.round(logCons[d1cent], 2)))\n",
    "    for i in range(nDisps-1):\n",
    "        print('Family ' + str(i+1) + ': ' + str(np.round(profs[2][i], 3)) + ' /// sum = ' + str(np.round(np.sum(profs[2][i]), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total contrast = 0.33\n",
      "Family 1: [ 0.325] /// sum = 0.33\n",
      "Family 2: [ 0.05   0.224  0.05 ] /// sum = 0.32\n"
     ]
    }
   ],
   "source": [
    "profs.append([]);\n",
    "d1cent = -4;\n",
    "d2cent = 4;\n",
    "d3cent = 2;\n",
    "profs[3].append([logCons[d1cent]]);\n",
    "profs[3].append([logCons[d2cent-4], logCons[d2cent], logCons[d2cent-4]]);\n",
    "# profs[3].append([logCons[d3cent-2], logCons[d3cent-1], logCons[d3cent], logCons[d3cent-1], logCons[d3cent-2]]);\n",
    "# profs.append([logCons[0], logCons[1], logCons[2], logCons[3], logCons[2], logCons[1], logCons[0]])\n",
    "\n",
    "if verbose:\n",
    "    print('Total contrast = ' + str(np.round(logCons[d1cent], 2)))\n",
    "    for i in range(nDisps-2):\n",
    "        print('Family ' + str(i+1) + ': ' + str(np.round(profs[3][i], 3)) + ' /// sum = ' + str(np.round(np.sum(profs[3][i]), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check the ratios; note that I changed the \"formula\" for the the third level of dispersion at the lowest contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total contrasts: [ 0.325  0.473  0.688  1.   ]\n",
      "\n",
      "Dispersion level: 1\n",
      "The ratio of contrasts by component are: \n",
      "\tratio: [ 1.]\n",
      "\tratio: [ 0.688]\n",
      "\tratio: [ 0.473]\n",
      "\tratio: [ 0.325]\n",
      "\n",
      "Dispersion level: 2\n",
      "The ratio of contrasts by component are: \n",
      "\tratio: [ 1.  1.  1.]\n",
      "\tratio: [ 0.688  0.688  0.688]\n",
      "\tratio: [ 0.473  0.473  0.473]\n",
      "\tratio: [ 0.325  0.325  0.325]\n",
      "\n",
      "Dispersion level: 3\n",
      "The ratio of contrasts by component are: \n",
      "\tratio: [ 1.  1.  1.  1.  1.]\n",
      "\tratio: [ 0.688  0.688  0.688  0.688  0.688]\n",
      "\tratio: [ 0.473  0.473  0.473  0.473  0.473]\n",
      "\n",
      "Dispersion level: 4\n",
      "The ratio of contrasts by component are: \n",
      "\tratio: [ 1.  1.  1.  1.  1.  1.  1.]\n",
      "\tratio: [ 0.688  0.688  0.688  0.688  0.688  0.688  0.688]\n"
     ]
    }
   ],
   "source": [
    "print('Total contrasts: ' + str(np.round(logCons[5:], 3)))\n",
    "for d in range(nDisps):\n",
    "    print('\\nDispersion level: ' + str(d+1));\n",
    "    print('The ratio of contrasts by component are: ')\n",
    "    for c in range(len(profs[d])): # how many contrasts?\n",
    "        rat = np.divide(profs[c][d], profs[0][d]);\n",
    "        print('\\tratio: ' + str(np.round(rat, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how many conditions? I.e. how much experimental time will be needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment length (in minutes) without blanks: 27.17\n"
     ]
    }
   ],
   "source": [
    "nConds = nCons*nSfCenters[0] + nSfMixCons*nSfCenters[1] + nSfMixCons*nSfCenters[2]\n",
    "if verbose:\n",
    "    print('Experiment length (in minutes) without blanks: ' + str(np.round(nConds*10/60.0, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast and opacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expo works in layers, and thus opacity must be used rather than contrast (or contrast alone, per se) to manipulate the effective contrast of each stimulus component. The following code, inherited from Robbe Goris, allows one to convert between opacity and contrast.\n",
    "\n",
    "As coded in Expo, I used contrast to go between overall contrast levels (i.e. total contrast of 1 or 0.68 or etc...) and opacity to determine the contrast of each grating <i>within</i> a given total contrast level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nGrats = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contrast to opacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, convert the desired contrast distribution into a vector of length nGrats with 0 for no grating and ordered highest to lowest contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dispInd = 3; # which dispersion level [0-3]?\n",
    "totalConInd = 0; # which total contrast level [0-3]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conSort = np.zeros((nGrats, ))\n",
    "curr_cons = profs[totalConInd][dispInd]\n",
    "# conSort[nGrats-len(curr_cons):nGrats] = np.sort(curr_cons)\n",
    "conSort[0:len(curr_cons)] = np.flip(np.sort(curr_cons), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32517246,  0.15376456,  0.15376456,  0.10573713,  0.10573713,\n",
       "        0.07271077,  0.07271077])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opac = np.zeros((nGrats, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opac[nGrats-1] = conSort[nGrats-1]\n",
    "opac[nGrats-2] = conSort[nGrats-2]/((1 - opac[nGrats-1]));\n",
    "opac[nGrats-3] = conSort[nGrats-3]/((1 - opac[nGrats-1])*(1 - opac[nGrats-2]));\n",
    "opac[nGrats-4] = conSort[nGrats-4]/((1 - opac[nGrats-1])*(1 - opac[nGrats-2])*(1 - opac[nGrats-3]));\n",
    "opac[nGrats-5] = conSort[nGrats-5]/((1 - opac[nGrats-1])*(1 - opac[nGrats-2])*(1 - opac[nGrats-3])*(1 - opac[nGrats-4]));\n",
    "opac[nGrats-6] = conSort[nGrats-6]/((1 - opac[nGrats-1])*(1 - opac[nGrats-2])*(1 - opac[nGrats-3])*(1 - opac[nGrats-4])*(1 - opac[nGrats-5]));\n",
    "opac[nGrats-7] = conSort[nGrats-7]/((1 - opac[nGrats-1])*(1 - opac[nGrats-2])*(1 - opac[nGrats-3])*(1 - opac[nGrats-4])*(1 - opac[nGrats-5])*(1 - opac[nGrats-6]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opacity values: [ 0.9690006   0.3142287   0.23909743  0.14120098  0.12373016  0.07841218\n",
      "  0.07271077]\n"
     ]
    }
   ],
   "source": [
    "if verbose:\n",
    "    print('Opacity values: ' + str(np.transpose(opac)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opacity to contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons = np.zeros((nGrats, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = dict()\n",
    "# usually one constant value across each component for a given value \n",
    "temp['con'] = 0.688*np.ones((nGrats, 1))\n",
    "# input by hand from Expo to check\n",
    "temp['opa'] = opac\n",
    "# temp['opa'] = [ 0.993,  0.18170423,  0.15376456,  0.0,  0.0,  0.,          0.        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cons[nGrats-1] = temp['con'][nGrats-1]*temp['opa'][nGrats-1];\n",
    "cons[nGrats-2] = temp['con'][nGrats-2]*temp['opa'][nGrats-2]*(1-temp['opa'][nGrats-1]);\n",
    "cons[nGrats-3] = temp['con'][nGrats-3]*temp['opa'][nGrats-3]*(1-temp['opa'][nGrats-1])*(1-temp['opa'][nGrats-2]);\n",
    "cons[nGrats-4] = temp['con'][nGrats-4]*temp['opa'][nGrats-4]*(1-temp['opa'][nGrats-1])*(1-temp['opa'][nGrats-2])*(1-temp['opa'][nGrats-3]);\n",
    "cons[nGrats-5] = temp['con'][nGrats-5]*temp['opa'][nGrats-5]*(1-temp['opa'][nGrats-1])*(1-temp['opa'][nGrats-2])*(1-temp['opa'][nGrats-3])*(1-temp['opa'][nGrats-4]);\n",
    "cons[nGrats-6] = temp['con'][nGrats-6]*temp['opa'][nGrats-6]*(1-temp['opa'][nGrats-1])*(1-temp['opa'][nGrats-2])*(1-temp['opa'][nGrats-3])*(1-temp['opa'][nGrats-4])*(1-temp['opa'][nGrats-5]);\n",
    "cons[nGrats-7] = temp['con'][nGrats-7]*temp['opa'][nGrats-7]*(1-temp['opa'][nGrats-1])*(1-temp['opa'][nGrats-2])*(1-temp['opa'][nGrats-3])*(1-temp['opa'][nGrats-4])*(1-temp['opa'][nGrats-5])*(1-temp['opa'][nGrats-6]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Psychophysics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using my pilot CSF measurements (and other CSF data from the literature), we can get a sense for what spatial frequency-contrast values are generally visible. In the code below, I'll get a sense for the SFxContrast content of each component of the stimuli used in the psychophysics given a particular range of SF centers and dispersion levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters to set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SF_REF = 1;\n",
    "grat_step = 0.5059; # spacing between adjacent SFs in mixture stimuli in octaves; 0.5059 octaves is spacing in logspace(log10(0.3), log10(10), 11)\n",
    "cent_step = 0.25; # i.e. space the center of each distribution X octaves apart\n",
    "n_cent_steps = 11; # must be odd s.t. we can symmetrically go about SF_REF\n",
    "if np.mod(n_cent_steps, 2) == 0:\n",
    "    n_cent_steps = n_cent_steps+1;\n",
    "    \n",
    "sf_round = 3; # round SFs to 3 digits\n",
    "incMidSamp = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freqMax = np.power(2, np.log2(SF_REF) + np.floor(n_cent_steps/2)*cent_step);                                                                                                                                               \n",
    "freqMin = np.power(2, np.log2(SF_REF) - np.floor(n_cent_steps/2)*cent_step);                                                                                                                                               \n",
    "freqCenters = np.logspace(np.log10(freqMin), np.log10(freqMax), n_cent_steps); \n",
    "\n",
    "if incMidSamp:                                                                                                                                                                                              \n",
    "    logMid = lambda a,b: np.power(2, (np.log2(a) + np.log2(b))/2);                                                                                                                                                             \n",
    "    ref_ind = np.where(np.round(freqCenters, sf_round) == np.round(SF_REF, sf_round))[0]; # always the same; take only 1 if the value is found > 1 time                                                  \n",
    "    lowMid = logMid(freqCenters[ref_ind-1], freqCenters[ref_ind]);                                                                                                                                          \n",
    "    highMid = logMid(freqCenters[ref_ind], freqCenters[ref_ind+1]);                                                                                                                                         \n",
    "    freqCenters = np.sort(np.concatenate((freqCenters, freqCenters[ref_ind], lowMid, lowMid, highMid, highMid)));\n",
    "freqCenters = np.round(freqCenters, sf_round);  \n",
    "\n",
    "num_gratings = 7; # fixed from sfMixAlt physiology experiments                                                                                                                                              \n",
    "freqMax = np.power(2, np.log2(1) + np.floor(num_gratings/2)*grat_step); # For expl. on log2(1), see comment below sfVec                                                                                                    \n",
    "freqMin = np.power(2, np.log2(1) - np.floor(num_gratings/2)*grat_step);                                                                                                                                                    \n",
    "sfVec = np.logspace(np.log10(freqMin), np.log10(freqMax), num_gratings);\n",
    "# relative to a particular sfCenter, sfVec contains the factors which can                                                                                                                                  \n",
    "# be used to multiply the sfCenter to create the dispersed grating  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All possible spatial frequencies, regardless of the contrast used. Note that it might be wise to restrict the range of sf centers (e.g. by reducing the number of sf centers) for higher contrasts, as is done in the sfMixAlt physiology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum spatial frequency: 0.147 cpd\n",
      "Maximum spatial frequency: 6.809 cpd\n"
     ]
    }
   ],
   "source": [
    "allSfs = np.unique([i*sfVec for i in freqCenters])\n",
    "print('Minimum spatial frequency: ' + str(np.round(allSfs[0], 3)) + ' cpd')\n",
    "print('Maximum spatial frequency: ' + str(np.round(allSfs[-1], 3)) + ' cpd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
